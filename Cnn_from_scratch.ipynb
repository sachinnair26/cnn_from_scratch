{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cnn from scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYyjxws_TkzI",
        "colab_type": "code",
        "outputId": "e75da988-7877-43f7-8c69-38ac07c37995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np \n",
        "import cv2\n",
        "from keras.datasets import mnist\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTu0UhTOTr4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Convolution:\n",
        "    def __init__ (self,filters,filter_size):\n",
        "      self.filters = filters\n",
        "      self.filter_size = filter_size\n",
        "      self.conv_filter = np.random.randn(filters,filter_size,filter_size)/(filter_size*filter_size)\n",
        "\n",
        "    def image_region(self,image):\n",
        "      height,width = np.shape(image)\n",
        "      self.image = image\n",
        "      for i in range(height-self.filter_size+1):\n",
        "        for j in range(width-self.filter_size+1): \n",
        "          img_patch = image[i:(i+self.filter_size),j:(j+self.filter_size)]\n",
        "          yield img_patch,i,j\n",
        "    \n",
        "    def forward_prop(self,image):\n",
        "      height,width = np.shape(image)\n",
        "      convo_output = np.zeros((height-self.filter_size+1,width-self.filter_size+1,self.filters))\n",
        "      for img_patch,i,j in self.image_region(image):\n",
        "        convo_output[i,j] = np.sum(img_patch*self.conv_filter,axis=(1,2))\n",
        "      return convo_output\n",
        "    \n",
        "\n",
        "    def back_prop(self,dL_dmaxpool,learning_rate):\n",
        "      dL_dconv = np.zeros(np.shape(self.conv_filter))\n",
        "      for image_patch,i,j in self.image_region(self.image):\n",
        "        for k in range(self.filters):\n",
        "          dL_dconv[k] +=image_patch*dL_dmaxpool[i,j,k]\n",
        "\n",
        "      self.conv_filter -= learning_rate*dL_dconv\n",
        "      return dL_dconv\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWganKBX-U80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Maxpool:\n",
        "  def __init__(self,filter_size):\n",
        "    self.filter_size = filter_size\n",
        "  \n",
        "  def image_region(self,image):\n",
        "    new_height = np.shape(image)[0]//self.filter_size\n",
        "    new_width = np.shape(image)[1]//self.filter_size\n",
        "    self.image = image\n",
        "    for i in range(new_height):\n",
        "      for j in range(new_width):\n",
        "        image_patch = image[(i*self.filter_size):(i*self.filter_size+self.filter_size),(j*self.filter_size):(j*self.filter_size+self.filter_size)]\n",
        "        yield image_patch,i,j\n",
        "\n",
        "  def forward_prop(self,image):\n",
        "    height,width,filters = np.shape(image)\n",
        "    output1 = np.zeros((height//self.filter_size,width//self.filter_size,filters))\n",
        "    \n",
        "\n",
        "    for image_patch,i,j in self.image_region(image):\n",
        "      # print(i,j)\n",
        "      output1[i,j] = np.amax(image_patch,axis=(0,1))\n",
        "    return output1\n",
        "  \n",
        "  def back_prop(self,dL_dx):\n",
        "    dL_dmaxpool = np.zeros(np.shape(self.image))\n",
        "    for image_patch,i,j in self.image_region(self.image):\n",
        "      height,width,filters = np.shape(image_patch)\n",
        "      max_value = np.amax(image_patch,axis=(0,1))\n",
        "\n",
        "      for t in range(height):\n",
        "        for u in range(width):\n",
        "          for v in range(filters):\n",
        "            if image_patch[t,u,v] == max_value[v]:\n",
        "              dL_dmaxpool[i*self.filter_size+t,j*self.filter_size+u,v] = dL_dx[i,j,v]\n",
        "\n",
        "        return dL_dmaxpool\n",
        "\n",
        "           \n",
        "      \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFbAt97-h2uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Softmax:\n",
        "  def __init__(self,input_node,softmax_node):\n",
        "    self.weight = np.random.randn(input_node,softmax_node)/input_node\n",
        "    self.bias = np.zeros(softmax_node)\n",
        "  \n",
        "  def forward_prop(self,image):\n",
        "    self.original_image_size = np.shape(image)\n",
        "    flat_image = image.flatten()\n",
        "    self.flat_image = flat_image\n",
        "    output_value = np.dot(self.flat_image,self.weight) + self.bias\n",
        "    self.output_value = output_value\n",
        "    output_exp = np.exp(self.output_value)\n",
        "    return output_exp/np.sum(output_exp,axis = 0)\n",
        "\n",
        "  def back_prop(self,dL_out,learning_rate):\n",
        "    for i,grad in enumerate(dL_out):\n",
        "      if grad == 0:\n",
        "        continue\n",
        "      transformation_eqn = np.exp(self.output_value)\n",
        "      S_total = np.sum(transformation_eqn)\n",
        "\n",
        "      dy_dz = -transformation_eqn[i]*transformation_eqn/(S_total**2)\n",
        "      dy_dz[i]= transformation_eqn[i]*(S_total - transformation_eqn[i])/(S_total**2)\n",
        "\n",
        "      dz_dw = self.flat_image\n",
        "      dz_dbias = 1\n",
        "      dz_dx = self.weight\n",
        "\n",
        "      dL_dz = grad*dy_dz\n",
        "      dL_dw = dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
        "      dL_dbias = dL_dz*dz_dbias\n",
        "      dL_dx = dz_dx @ dL_dz\n",
        "      self.weight -= learning_rate*dL_dw \n",
        "      self.bias -=learning_rate*dL_dbias\n",
        "\n",
        "      return dL_dx.reshape(self.original_image_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUSoW4pBbuUB",
        "colab_type": "code",
        "outputId": "ed330270-4247-4014-cfec-a2105f8d2655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
        "\n",
        "train_images = X_train[:1500]\n",
        "train_labels = y_train[:1500]\n",
        "test_images = X_test[:1500]\n",
        "test_labels = y_train[:1500]\n",
        "\n",
        "conv = Convolution(8,3)\n",
        "pool =Maxpool(2)\n",
        "softmax = Softmax(13*13*8,10)\n",
        "\n",
        "def cnn_forward_prop(image,label):\n",
        "  out_p =conv.forward_prop((image/255)-0.5)\n",
        "  out_p =pool.forward_prop(out_p)\n",
        "  out_p =softmax.forward_prop(out_p)\n",
        "\n",
        "  cross_entropy_loss = -np.log(out_p[label])\n",
        "  accurecy = 1 if np.argmax(out_p) == label else 0 \n",
        "  return out_p,cross_entropy_loss,accurecy\n",
        "\n",
        "\n",
        "def trainning_cnn(image,label,learn_rate=.005):\n",
        "  out,loss,accurecy = cnn_forward_prop(image,label)\n",
        "  gradient = np.zeros(10)\n",
        "  gradient[label] = -1/out[label]\n",
        "  grad_back = softmax.back_prop(gradient,learn_rate)\n",
        "  grad_back = pool.back_prop(grad_back)\n",
        "  grad_back = conv.back_prop(grad_back,learn_rate)\n",
        "\n",
        "  return loss,accurecy\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXRyge6n5c9K",
        "colab_type": "code",
        "outputId": "f102490a-c54a-4dfb-db90-dd857c699cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(4):\n",
        "  print(\"Epoch -->%d\",(epoch+1))\n",
        "  shuffle_data = np.random.permutation(len(train_images))\n",
        "  train_images = train_images[shuffle_data]\n",
        "  train_labels = train_labels[shuffle_data]\n",
        "\n",
        "\n",
        "  loss = 0 \n",
        "  accu = 0\n",
        "  for i,(im,label) in enumerate(zip(train_images,train_labels)):\n",
        "    if i%100 == 0:\n",
        "      print(\"%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%%\",(i+1,loss/100,accu))\n",
        "      loss = 0 \n",
        "      accu = 0\n",
        "    los,acu = trainning_cnn(im,label)\n",
        "    loss+=los\n",
        "    accu +=acu\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch -->%d 1\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1, 0.0, 0)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (101, 2.2185442160168334, 16)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (201, 2.0361208297774187, 35)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (301, 1.874230502368805, 44)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (401, 1.699728795839908, 55)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (501, 1.6599321132103901, 55)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (601, 1.4813138573198588, 68)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (701, 1.3683083175329347, 68)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (801, 1.229172515060484, 78)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (901, 1.1348529504207152, 78)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1001, 1.259355425930504, 68)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1101, 1.1529858356345462, 76)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1201, 0.9138331369371879, 88)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1301, 0.9873905147294133, 80)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1401, 0.8941739536441956, 78)\n",
            "Epoch -->%d 2\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1, 0.0, 0)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (101, 0.8044679179679384, 90)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (201, 0.7526715744645495, 86)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (301, 0.8444413236226871, 83)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (401, 0.8038430235089205, 83)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (501, 0.9790307116119119, 72)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (601, 0.7781005894269903, 84)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (701, 0.7584908895891368, 82)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (801, 0.7907389262549586, 85)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (901, 0.7900640905349866, 85)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1001, 0.7882064245979198, 86)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1101, 0.6900296621475871, 85)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1201, 0.7297921192295349, 82)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1301, 0.7456604557193245, 79)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1401, 0.7345248081390122, 80)\n",
            "Epoch -->%d 3\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1, 0.0, 0)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (101, 0.6128564657058595, 89)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (201, 0.6703730491847117, 87)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (301, 0.6120556428339775, 88)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (401, 0.646593073553563, 84)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (501, 0.6740876685938164, 79)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (601, 0.7393898647797141, 82)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (701, 0.6444682580489656, 89)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (801, 0.6804608631272498, 84)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (901, 0.5886824985620003, 83)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1001, 0.5251369686213365, 89)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1101, 0.6093479848116186, 85)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1201, 0.5610672631999549, 89)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1301, 0.7158441090733342, 85)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1401, 0.42224813891640267, 94)\n",
            "Epoch -->%d 4\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1, 0.0, 0)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (101, 0.6066889839742035, 86)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (201, 0.39364243335053106, 93)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (301, 0.6520966680208338, 80)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (401, 0.6039239463678497, 86)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (501, 0.5896924471960723, 90)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (601, 0.6017452874138808, 86)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (701, 0.6066993836114308, 84)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (801, 0.5314657163681832, 90)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (901, 0.6124118763346683, 86)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1001, 0.5622152582165568, 84)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1101, 0.525973871682884, 88)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1201, 0.4743280464949008, 92)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1301, 0.5321216447020759, 85)\n",
            "%d steps out of 100 steps:Avg loss %.2f and accurecy:%d%% (1401, 0.5374519492326272, 84)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9rrnYLk7dr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b285ef36-3407-4563-b480-d3232d6c8225"
      },
      "source": [
        "#Test things\n",
        "test_loss = 0\n",
        "test_accu = 0\n",
        "\n",
        "for im,labels in zip(test_images,test_labels):\n",
        "  out_value,los,acu = cnn_forward_prop(im,labels)\n",
        "  test_loss +=los\n",
        "  test_accu +=acu\n",
        "\n",
        "test_count = len(test_images)\n",
        "print(\"Test Loss %.2f\",test_loss/test_count)\n",
        "print(\"Test Accurecy %.2f\",test_accu/test_count)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss %.2f 4.0718563840058675\n",
            "Test Accurecy %.2f 0.09933333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}